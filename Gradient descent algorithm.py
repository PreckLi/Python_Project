"""æ¢¯åº¦ä¸‹é™ç®—æ³•"""

import numpy as np
from matplotlib import pyplot as plt
#1.é‡‡æ ·æ•°æ®
#çœŸå®æ¨¡å‹ y=1.477x+0.089
#æ¨¡æ‹ŸçœŸå®æ ·æœ¬çš„è§‚æµ‹è¯¯å·®,æ·»åŠ è¯¯å·®è‡ªå˜é‡E,é‡‡æ ·è‡ªå‡å€¼ä¸º0,æ ‡å‡†å·®ä¸º0.01çš„é«˜æ–¯åˆ†å¸ƒ y=1.477x+0.089+E,E~N(0,0.01^2)
#éšæœºé‡‡æ ·n=100æ¬¡,è·å¾—nä¸ªæ ·æœ¬çš„è®­ç»ƒæ•°æ®é›†Dtrain


#2.è®¡ç®—è¯¯å·®
#å¾ªç¯è®¡ç®—æ¯ä¸ªç‚¹(x(i),y(i))é¢„æµ‹å€¼ä¸çœŸå®å€¼ä¹‹é—´å·®çš„å¹³æ–¹å¹¶ç´¯åŠ 
def mse(b,w,points):
    #æ ¹æ®å½“å‰w,bå‚æ•°è®¡ç®—å‡æ–¹å·®æŸå¤±
    totalError=0
    for i in range(0,len(points)):  #è¿­ä»£æ‰€æœ‰çš„ç‚¹
        x=points[i,0]   #iç‚¹è¾“å…¥x
        y=points[i,1]   #iç‚¹è¾“å‡ºy
        #è®¡ç®—å·®çš„å¹³æ–¹,å¹¶ç´¯åŠ 
        totalError+=(y-(w*x+b))**2
    #å°†ç´¯åŠ çš„è¯¯å·®æ±‚å¹³å‡ï¼Œå¾—å‡æ–¹å·®
    return totalError/float(len(points))

#3.æ¢¯åº¦è®¡ç®—
#è®¡ç®—lå¯¹wåå¯¼æ•°,å’Œlå¯¹bçš„åå¯¼æ•°
def step_gradient(b_current,w_current,points,lr):
    #è¯¯å·®åœ¨æ‰€æœ‰ç‚¹ä¸Šçš„å¯¼æ•°,å¹¶æ›´æ–°w,b,lrä¸ºå­¦ä¹ ç‡
    b_gradient=0
    w_gradient=0
    M=float(len(points))    #æ ·æœ¬æ€»æ•°
    for i in range(0,len(points)):
        x=points[i,0]
        y=points[i,1]
        # æ±‚è¯¯å·®å‡½æ•°å¯¹bçš„å¯¼æ•°ï¼šgrad_b=2(wx+b-y)
        b_gradient+=(2/M)*((w_current*x+b_current)-y)
        # æ±‚è¯¯å·®å‡½æ•°å¯¹wçš„å¯¼æ•°ï¼šgrad_w=2(wx+b-y)*x
        w_gradient+=(2/M)*x*((w_current*x+b_current)-y)
    #æ ¹æ®æ¢¯åº¦ä¸‹é™ç®—æ³•æ›´æ–°w',b',lrä¸ºå­¦ä¹ ç‡
    new_b=b_current-(lr*b_gradient)
    new_w=w_current-(lr*w_gradient)
    return [new_b,new_w]

#4ã€‚æ¢¯åº¦æ›´æ–°
#åœ¨è®¡ç®—å‡ºè¯¯å·®å‡½æ•°åœ¨ğ‘¤å’Œğ‘å¤„çš„æ¢¯åº¦åï¼Œæˆ‘ä»¬å¯ä»¥æ›´æ–°ğ‘¤å’Œğ‘çš„å€¼ã€‚æˆ‘ä»¬æŠŠ
# å¯¹æ•°æ®é›†çš„æ‰€æœ‰æ ·æœ¬è®­ç»ƒä¸€æ¬¡ç§°ä¸ºä¸€ä¸ª Epochï¼Œå…±å¾ªç¯è¿­ä»£ num_iterations ä¸ª Epochã€‚
def gradient_descent(points,starting_b,starting_w,lr,num_iterations):
    #å¾ªç¯æ›´æ–°w,bå¤šæ¬¡
    b=starting_b    #bçš„åˆå§‹å€¼
    w=starting_w    #wçš„åˆå§‹å€¼
    #æ ¹æ®æ¢¯åº¦ä¸‹é™ç®—æ³•æ›´æ–°å¤šæ¬¡
    for step in range(num_iterations):
        b,w=step_gradient(b,w,np.array(points),lr)
        loss=mse(b,w,points)    #è®¡ç®—å½“å‰å‡æ–¹å·®,ç›‘æ§è®­ç»ƒè¿›åº¦
        if step%50==0:  #æ‰“å°è¯¯å·®å’Œå®æ—¶w,bå€¼
            print(f"iteration:{step},loss:{loss},w:{w},b:{b}")
        wlist.append(w)
        blist.append(b)
        losslist.append(loss)

    return [b,w]    #è¿”å›æœ€åä¸€æ¬¡w,b

#ä¸»å‡½æ•°
def main():
    #åŠ è½½è®­ç»ƒé›†æ•°æ®
    lr=0.01
    initial_b=0 #åˆå§‹åŒ–b
    initial_w=0 #åˆå§‹åŒ–w
    num_iterations=1000
    #è®­ç»ƒ1000æ¬¡ï¼Œè¿”å›æœ€ä¼˜w*,b*å’Œè®­ç»ƒLossçš„ä¸‹é™è¿‡ç¨‹
    [b,w]=gradient_descent(data,initial_b,initial_w,lr,num_iterations)
    loss=mse(b,w,data)  #è®¡ç®—æœ€ä¼˜æ•°å€¼è§£w,bä¸Šçš„å‡æ–¹å·®
    print(f'Final loss:{loss},w:{w},b:{b}')

    plt.plot(losslist)
    plt.show()

if __name__ == '__main__':
    data = []
    wlist=[]
    blist=[]
    losslist=[]
    for i in range(100):
        x = np.random.uniform(-10, 10.)  # éšæœºé‡‡æ ·è¾“å…¥x
        # é‡‡æ ·é«˜æ–¯å™ªå£°
        eps = np.random.normal(0., 0.01)  # ç”Ÿæˆæ­£æ€åˆ†å¸ƒçš„æ¦‚ç‡å¯†åº¦
        # å¾—åˆ°æ¨¡å‹è¾“å‡º
        y = 1.477 * x + 0.089 + eps
        data.append([x, y])  # ä¿å­˜æ ·æœ¬ç‚¹
    data = np.array(data)  # è½¬æ¢ä¸º2D numpuæ•°ç»„constant

    main()






